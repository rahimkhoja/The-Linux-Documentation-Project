<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML
><HEAD
><TITLE
>Internet Specific Commands</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.7"><LINK
REL="HOME"
TITLE="GNU/Linux Command-Line Tools Summary"
HREF="index.html"><LINK
REL="UP"
TITLE="Network Commands"
HREF="network-commands.html"><LINK
REL="PREVIOUS"
TITLE="Network Configuration "
HREF="network-configuration.html"><LINK
REL="NEXT"
TITLE="Remote Administration Related"
HREF="remote-administration.html"></HEAD
><BODY
CLASS="SECT1"
BGCOLOR="#FFFFFF"
TEXT="#000000"
LINK="#0000FF"
VLINK="#840084"
ALINK="#0000FF"
><DIV
CLASS="NAVHEADER"
><TABLE
SUMMARY="Header navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="3"
ALIGN="center"
>GNU/Linux Command-Line Tools Summary</TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="bottom"
><A
HREF="network-configuration.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="80%"
ALIGN="center"
VALIGN="bottom"
>Chapter 13. Network Commands</TD
><TD
WIDTH="10%"
ALIGN="right"
VALIGN="bottom"
><A
HREF="remote-administration.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="SECT1"
><H1
CLASS="SECT1"
><A
NAME="INTERNET-SPECIFIC-COMMANDS"
></A
>13.2. Internet Specific Commands</H1
><P
>Note that should DNS not be configured correctly on your machine, you need to edit &#8220;/etc/resolv.conf&#8221; to make things work...</P
><P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
>host</DT
><DD
><P
>Performs a simple lookup of an internet address (using the Domain Name System, DNS). Simply type:</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="90%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>host ip_address</PRE
></FONT
></TD
></TR
></TABLE
><P
>or</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="90%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>host domain_name</PRE
></FONT
></TD
></TR
></TABLE
></DD
><DT
>dig</DT
><DD
><P
>The "domain information groper" tool. More advanced then <EM
>host</EM
>... If you give a hostname as an argument to output information about that host, including it's IP address, hostname and various other information. </P
><P
>For example, to look up information about &#8220;www.amazon.com&#8221; type:</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="90%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>dig www.amazon.com</PRE
></FONT
></TD
></TR
></TABLE
><P
>To find the host name for a given IP address (ie a reverse lookup), use <EM
>dig</EM
> with the <EM
>`-x'</EM
> option.</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="90%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>dig -x 100.42.30.95</PRE
></FONT
></TD
></TR
></TABLE
><P
>This will look up the address (which may or may not exist) and returns the address of the host, for example if that was the address of &#8220;http://slashdot.org&#8221; then it would return &#8220;http://slashdot.org&#8221;.</P
><P
><EM
>dig</EM
> takes a huge number of options (at the point of being too many), refer to the manual page for more information.</P
><P
></P
></DD
><DT
>whois</DT
><DD
><P
>(now <SPAN
CLASS="ACRONYM"
>BW</SPAN
> whois) is used to look up the contact information from the &#8220;whois&#8221; databases, the servers are only likely to hold major sites. Note that contact information is likely to be hidden or restricted as it is often abused by crackers and others looking for a way to cause malicious damage to organisation's.</P
></DD
><DT
>wget</DT
><DD
><P
>(GNU Web get) used to download files from the World Wide Web.</P
><P
>To archive a single web-site, use the <EM
>-m</EM
> or <EM
>--mirror</EM
> (mirror) option.</P
><P
>Use<EM
> </EM
>the<EM
> -nc </EM
>(no clobber) option to stop <EM
>wget</EM
> from overwriting a file if you already have it.</P
><P
>Use the <EM
>-c</EM
> or <EM
>--continue</EM
> option to continue a file that was unfinished by wget or another program.</P
><P
>Simple usage example:</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="90%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>wget url_for_file</PRE
></FONT
></TD
></TR
></TABLE
><P
>This would simply get a file from a site. </P
><P
><EM
>wget</EM
> can also retrieve multiple files using standard wildcards, the same as the type used in bash, like *, [ ], ?. Simply use <EM
>wget</EM
> as per normal but use single quotation marks (' ') on the URL to prevent bash from expanding the wildcards. There are complications if you are retrieving from a http site (see below...).</P
><P
>Advanced usage example, (used from <EM
>wget</EM
> manual page):</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="90%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>wget --spider --force-html -i bookmarks.html</PRE
></FONT
></TD
></TR
></TABLE
><P
>This will parse the file bookmarks.html and check that all the links exist.</P
><P
>Advanced usage: this is how you can download multiple files using http (using a wildcard...).</P
><P
>Notes: http doesn't support downloading using standard wildcards, ftp does so you may use wildcards with ftp and it will work fine. A work-around for this http limitation is shown below:</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="90%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>wget -r -l1 --no-parent -A.gif http://www.website.com<A
NAME="AEN8967"
HREF="#FTN.AEN8967"
><SPAN
CLASS="footnote"
>[1]</SPAN
></A
></PRE
></FONT
></TD
></TR
></TABLE
><P
>This will download (recursively), to a depth of one, in other words in the current directory and not below that. This command will ignore references to the parent directory, and downloads anything that ends in &#8220;.gif&#8221;. If you wanted to download say, anything that ends with &#8220;.pdf&#8221; as well than add a <EM
>-A.pdf</EM
> before the website address. Simply change the website address and the type of file being downloaded to download something else. Note that doing <EM
>-A.gif</EM
> is the same as doing <EM
>-A &#8220;*.gif</EM
>&#8221; (double quotes only, single quotes will not work).</P
><P
><EM
>wget</EM
> has many more options refer to the examples section of the manual page, this tool is very well documented.</P
><DIV
CLASS="NOTE"
><P
></P
><TABLE
CLASS="NOTE"
WIDTH="90%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/note.gif"
HSPACE="5"
ALT="Note"></TD
><TH
ALIGN="LEFT"
VALIGN="CENTER"
><B
>Alternative website downloaders</B
></TH
></TR
><TR
><TD
>&nbsp;</TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
><P
>You may like to try alternatives like httrack. A full <SPAN
CLASS="ACRONYM"
>GUI</SPAN
> website downloader written in python and available for GNU/Linux </P
></TD
></TR
></TABLE
></DIV
></DD
><DT
>curl</DT
><DD
><P
><EM
>curl</EM
> is another remote downloader. This remote downloader is designed to work without user interaction and supports a variety of protocols, can upload/download and has a large number of tricks/work-arounds for various things. It can access dictionary servers (dict), ldap servers, ftp, http, gopher, see the manual page for full details. </P
><P
>To access the full manual (which is huge) for this command type:</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="90%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>curl -M</PRE
></FONT
></TD
></TR
></TABLE
><P
>For general usage you can use it like <EM
>wget</EM
>. You can also login using a user name by using the <EM
>-u</EM
> option and typing your username and password like this:</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="90%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>curl -u username:password http://www.placetodownload/file</PRE
></FONT
></TD
></TR
></TABLE
><P
>To upload using ftp you the <EM
>-T</EM
> option:</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="90%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>curl -T file_name ftp://ftp.uploadsite.com</PRE
></FONT
></TD
></TR
></TABLE
><P
>To continue a file use the <EM
>-C</EM
> option:</P
><TABLE
BORDER="1"
BGCOLOR="#E0E0E0"
WIDTH="90%"
><TR
><TD
><FONT
COLOR="#000000"
><PRE
CLASS="SCREEN"
>curl -C - -o file http://www.site.com</PRE
></FONT
></TD
></TR
></TABLE
></DD
></DL
></DIV
></DIV
><H3
CLASS="FOOTNOTES"
>Notes</H3
><TABLE
BORDER="0"
CLASS="FOOTNOTES"
WIDTH="100%"
><TR
><TD
ALIGN="LEFT"
VALIGN="TOP"
WIDTH="5%"
><A
NAME="FTN.AEN8967"
HREF="internet-specific-commands.html#AEN8967"
><SPAN
CLASS="footnote"
>[1]</SPAN
></A
></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
WIDTH="95%"
><P
>This way around the wildcard limitation has been adopted (with a tiny amount of editing) from <A
HREF="http://www.lns.cornell.edu/public/COMP/info/wget/wget_7.html"
TARGET="_top"
>wget manual page</A
>, see [9] in the <A
HREF="references.html"
><I
>Bibliography</I
></A
> for further information.</P
></TD
></TR
></TABLE
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
SUMMARY="Footer navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="network-configuration.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="index.html"
ACCESSKEY="H"
>Home</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="remote-administration.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
>Network Configuration</TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="network-commands.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>Remote Administration Related</TD
></TR
></TABLE
></DIV
></BODY
></HTML
>